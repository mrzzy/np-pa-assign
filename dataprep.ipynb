{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NP Predictive Analytics Assignment - Data Preparation\n",
    "In this notebook we prepare the dataset for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from data.dataset import *\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Load dataframe from EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(os.path.join(\"build\", \"dataset.feather\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and Outputs\n",
    "Extract & separate the target output variable `G3` from the rest of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = df[target_var]\n",
    "inputs_df = df.drop(columns=target_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset\n",
    "Set aside hold out test set for later cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, test_idxs = train_test_split(list(range(len(df))), \n",
    "                                         shuffle=True, \n",
    "                                         test_size=100)\n",
    "train_in_df, test_in_df = inputs_df.iloc[train_idxs], inputs_df.iloc[test_idxs]\n",
    "train_scores, test_scores = final_scores[train_idxs], final_scores[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Data Pipeline\n",
    "Build a Data Pipeline to preprocess the dataset:\n",
    "- numeric features - feature scale using Z-score transform\n",
    "- categorical features - feature extraction by one hot encoding\n",
    "- binary features - feature extraction by ordinal encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ColumnTransformer([\n",
    "    (\"num_pipeline\", StandardScaler(), num_features),\n",
    "    (\"cat_pipeline\", OneHotEncoder(), cat_features),\n",
    "    (\"bin_pipeline\", OrdinalEncoder(), bin_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "Use data pipeline to prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(train_in_df)\n",
    "train_data = pipeline.transform(train_in_df)\n",
    "test_data = pipeline.transform(test_in_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reducation\n",
    "Apply PCA to reduce no. of features, perserving 99% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99, svd_solver=\"full\")\n",
    "pca.fit(train_data)\n",
    "train_pca = pca.transform(train_data)\n",
    "test_pca = pca.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of PCA components: 45\n"
     ]
    }
   ],
   "source": [
    "print(f\"no. of PCA components: {train_data.shape[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit Data\n",
    "Commit prepared data and data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(os.path.join(\"build\", \"dataprep.npz\"),\n",
    "                    train_data=train_data,\n",
    "                    test_data=test_data,\n",
    "                    train_pca=train_pca,\n",
    "                    test_pca=test_pca,\n",
    "                    train_scores=train_scores,\n",
    "                    test_scores=test_scores,\n",
    "                    train_idxs=train_idxs, test_idxs=test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['build/dataprep.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump({\n",
    "    \"pca\": pca,\n",
    "    \"pipeline\": pipeline\n",
    "}, os.path.join(\"build\",\"dataprep.joblib\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
